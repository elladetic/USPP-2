{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Algorithm 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorly as tl\n",
    "import math \n",
    "#from matplotlib import pyplot\n",
    "#import keras\n",
    "from keras.datasets import mnist\n",
    "\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiplication(T, M, mode): \n",
    "    \n",
    "    descriptor = list(T.shape)\n",
    "    descriptor[mode] = M.shape[0]\n",
    "    pom = tl.unfold(T, mode)\n",
    "    \n",
    "    return (tl.fold( M @ pom, mode, descriptor))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HOSVD(T):\n",
    "\n",
    "    U1, _, _ = np.linalg.svd(tl.unfold(T, 0), full_matrices=False) \n",
    "    U2, _, _ = np.linalg.svd(tl.unfold(T, 1), full_matrices=False) \n",
    "    U3, _, _ = np.linalg.svd(tl.unfold(T, 2), full_matrices=False)\n",
    "\n",
    "    S = tl.tenalg.multi_mode_dot(T, [np.transpose(U1),np.transpose(U2),np.transpose(U3)], modes = [0,1,2], transpose=False)\n",
    "    \n",
    "    return(S, U1, U2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alg1_train(A_train, D_train,  k):\n",
    "    \n",
    "    tensor = [None] * k\n",
    "    \n",
    "    for i in range(k):\n",
    "\n",
    "        T = tl.vec_to_tensor(A_train[:, np.where(D_train == i)[1]], (int(math.sqrt(A_train.shape[0])),int(math.sqrt(A_train.shape[0])),A_train[:, np.where(D_train == i)[1]].shape[1]))\n",
    "        S, U1, U2 = HOSVD(T)\n",
    "    \n",
    "        tensor[i] = np.zeros((int(math.sqrt(A_train.shape[0])),int(math.sqrt(A_train.shape[0])), S.shape[2]))\n",
    "\n",
    "        for j in range(S.shape[2]):\n",
    "            \n",
    "            pom_1 = multiplication(tl.vec_to_tensor(S[:,:,j], (int(math.sqrt(A_train.shape[0])),int(math.sqrt(A_train.shape[0])),1)), U1, 0)\n",
    "            pom_2 = multiplication(pom_1, U2, 1)\n",
    "            \n",
    "            tensor[i][:, :, j] = np.reshape(pom_2 / np.linalg.norm(pom_2), (int(math.sqrt(A_train.shape[0])),int(math.sqrt(A_train.shape[0]))))\n",
    "            \n",
    "    return(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alg1_test(A_test, tensor,  k, l):\n",
    "        \n",
    "    digits = []\n",
    "\n",
    "    for i in range(A_test.shape[1]): \n",
    "        \n",
    "        D = np.reshape((A_test[:, i] / np.linalg.norm(A_test[:, i])), (int(math.sqrt(A_train.shape[0])),int(math.sqrt(A_train.shape[0]))))\n",
    "        max_R = np.NINF\n",
    "        digit = 0 \n",
    "    \n",
    "        for j in range(k):\n",
    "            \n",
    "            R = 0\n",
    "            \n",
    "            for z in range(l): \n",
    "                R += np.trace(np.matmul(np.transpose(D), tensor[j][:,:,z])) ** 2  \n",
    "                \n",
    "            if( R > max_R): \n",
    "                max_R = R\n",
    "                digit = j\n",
    "            \n",
    "        digits.append(digit)\n",
    "        \n",
    "    return digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Application of the algorithm for the MNIST digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
    "\n",
    "train_y = np.transpose(np.reshape(train_y, (60000,1)))\n",
    "test_y = np.transpose(np.reshape(test_y, (10000,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_train = np.empty([train_X.shape[1] ** 2, train_X.shape[0]])\n",
    "\n",
    "for i in range(train_X.shape[0]):\n",
    "    A_train[:,i] = np.reshape(train_X[i],(28*28,)) \n",
    "    \n",
    "D_train = train_y\n",
    "\n",
    "A_test = np.empty([test_X.shape[1] ** 2, test_X.shape[0]])\n",
    "\n",
    "for i in range(test_X.shape[0]):\n",
    "    A_test[:,i] = np.reshape(test_X[i],(test_X.shape[1]**2,))\n",
    "    \n",
    "D_test = test_y\n",
    "\n",
    "k = np.unique(D_train).size\n",
    "\n",
    "l = 30 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9574"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = alg1_train(A_train, D_train, k )\n",
    "\n",
    "predictions = alg1_test(A_test, tensor, k, l)\n",
    "\n",
    "accuracy = np.count_nonzero(predictions == D_test[0]) / len(D_test[0])\n",
    "\n",
    "accuracy"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eeb592eeb14baf80ba7e3ad598b9cc718d92fa62785d72005ca19f7c0e0c833d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
